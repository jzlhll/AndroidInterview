### AI Coding

**prompt engineering**

避免一句话需求，需要描述清楚。

结构化表示prompt，提示词编写框架CO-STAR框架: Context(上下文)、Objective(目标)、Style(风格名)、Tone(语气)、Audience(受众)、Response 回复)。
Context (上下文):  提供任务的上下文信息,有助于LLM了解正在E讨论的具体情景,确保其答复具有相关性。
Objective(目标):   明确你希望LLM执行的任务是什么,有助于LLM把回答的重点放在实现这一具体目标上。
Style(风格):   表明你希望LLM使用的写作风格,可以是鲁迅、余华等某个名人的写作风格,也可以是某个行业的某个专家,
如商业分析专家或首席执行官。
Tone(语气):   确定回复的态度,可确保LLM的回复与所需的情感或情绪背景符合,如正式的、幽默的、具有说服力的等。
Audience(受众):  确定回复的对象,根据受众(如初学者、儿童等)量身定制LLM的回复,确保其在所需的语境中是恰当的、
可以理解的。
Response(回复):明确回复格式,确保LLM按照下游任务所需的准确格式输出。例如,列表、JSON、专业报告等。



基于个人能力利用AI的态度：

简单功能：CRUD，搬砖类显著提效；

略难功能：编码转换，文档阅读总结；

很难功能：我自己都不熟悉，编写大型代码，会累积冗余代码，设计缺陷。



拆解任务颗粒度,  模块化，让AI实现模块化编写，并且每步可验证，必须review他的代码，git提交频繁便于回滚。

**推理（Reasoning）和规划（Planning）**

人工智能可以通过从历史数据中学到的模式和规律来理解信息，从而解决问题并完成任务。这种能力类似于人类的推理过程，即基于已有的知识和经验分析、判断新情况。更先进的 AI 系统还可以展示出更进一步的能力，通过制定计划、设计一系列行动来实现目标，从而解决更加复杂的问题。比如，当你让一个 AI 程序帮忙组织一次主题公园之旅时，AI 会利用推理能力将你提出的目标需求——游玩六项游乐设施并在中午游玩水上项目，分解成具体步骤，并在确保行程连贯性的同时避免走回头路。

**训练（Training）与推断（Inference）**

创建和使用一个 AI 系统包含两个关键步骤：训练和推断。“训练”就是 AI 系统的“学习过程”，在这一阶段，AI 会被“投喂”一个数据集，并基于这些数据学习如何去执行任务或做出预测。例如，给 AI 某社区内最近售出房屋的价格列表，以及每套房屋的卧室和浴室数量等多个变量。在训练阶段，AI 会调整其内部参数来决定每个因素在影响最终定价时的权重。在推断阶段，AI 则可以运用它学到的模式和参数，对即将上市的新房价格进行预测。

**锚定（Grounding）**

生成式人工智能可以创作故事、诗歌和笑话，也可以回答研究问题。但它们有时在区分事实与虚构方面会面临挑战，或者会因为训练数据已经过时而导致回应不准确，这种现象也被称为“幻觉”。所以，研发人员致力于通过锚定过程帮助人工智能更准确地与现实世界互动，他们将模型与数据和具体实例相连接并锚定，以此提高人工智能的准确性并产生更具上下文相关性和个性化的输出。

**编排（Orchestration）**

在处理人们的请求时，人工智能承担着繁重的任务。编排层的作用是引导它们按照正确的顺序执行所有任务，以进行最佳响应。例如，如果你向 Microsoft Copilot 询问 Ada Lovelace 是谁，然后问她何时出生，AI 的编排器会存储聊天历史，以了解你后续查询中的“她”是否指的是 Ada Lovelace。编排层还可以遵循 RAG 模式，在互联网上搜索新的信息添加到上下文中，并帮助模型给出更好的答案。这就像是一位指挥家指挥着小提琴、长笛和双簧管等乐器，按照乐谱演奏，共同产生作曲家心目中的声音。

**向量数据库 (Vector Database)**：专为高效存储和检索高维向量数据（嵌入）设计的数据库。文本、图像等内容经 AI 模型转换为向量后，可在此快速进行语义相似性搜索（如查找与 “AI 伦理” 相关的文档），是 RAG 的核心组件，也用于推荐系统、语义搜索。



**1. LLM (大语言模型)**
Large Language Model (LLM) 是指基于海量文本数据训练的、拥有巨大参数量（通常达数十亿甚至万亿级）的深度学习模型。其核心能力是理解和生成人类语言。通过在海量数据上学习统计规律，LLM能够完成诸如文本生成、翻译、问答、代码编写等多样任务。代表性的模型如GPT系列、LLaMA、PaLM等。它们已成为当前人工智能领域的基础技术，但其能力也受限于训练数据、算力成本及可能产生的“幻觉”问题。

**2. NLP (自然语言处理)**
自然语言处理是人工智能的一个子领域，旨在让计算机能够理解、解释和生成人类语言。它涵盖了从基础的词法、句法分析，到更复杂的语义理解、情感分析、机器翻译、对话系统等任务。传统NLP依赖规则和统计方法，而现代NLP则几乎完全由基于神经网络的深度学习（尤其是Transformer和LLM）所驱动，极大地提升了语言任务的性能和泛化能力。

**3. 神经网络**
神经网络是一种受人类大脑结构启发的计算模型，由大量相互连接的人工神经元（节点）组成。数据在输入层、隐藏层和输出层之间传播，通过调整神经元之间的连接权重来学习数据中的复杂模式。深度神经网络（DNN）具有多个隐藏层，能够进行“深度学习”，是计算机视觉、自然语言处理等AI领域的基石，为LLM提供了强大的表示和学习能力。

**4. Transformer模型和扩散模型（Diffusion model）**
Transformer是一种于2017年由Google在论文《Attention Is All You Need》中提出的神经网络架构。它摒弃了传统的循环（RNN）和卷积（CNN）结构，完全依赖**自注意力机制**来捕捉输入序列中所有元素之间的全局依赖关系。这种设计极大提高了并行计算效率，解决了长序列依赖问题，成为训练大型语言模型（如GPT、BERT）的事实标准架构，是当今LLM爆发的基础。

几十年来，人们一直在教 AI 系统如何理解和生成语言，Transformer 模型的出现为 AI 技术的发展带来了极大突破。在生成式人工智能的模型中，Transformer 模型无疑是理解和把握上下文及其细微差别最好、最快的模型。它擅长讲故事，会关注数据中的模式和规律并权衡不同输入的重要性，以帮助人工智能快速预测接下来的内容，从而生成文本。Transformer 模型之所以名声大噪，是因为它是 ChatGPT 中的 “T”，即“生成式预训练 Transformer”。

另一个模型是扩散模型（Diffusion models），通常用于图像创作。通过更渐进、更系统的方法，扩散模型可以从随机位置扩散像素，直到像素以形成提示中要求的图像的方式分布。扩散模型在生成最终结果之前会持续进行微小的调整。



**5. MCP (模型上下文协议)**
Model Context Protocol (MCP) 是一个由Anthropic提出的开放协议，旨在标准化LLM与应用和外部数据源之间的交互方式。它允许开发者通过定义标准的“资源”和“工具”接口，安全、可控地将外部数据（如数据库、API、文档）动态注入到LLM的上下文中，从而增强模型的能力而不必重新训练。MCP旨在提高LLM系统集成的效率和可复用性。

**6. RAG (Retrieval Augmented Generation 检索增强生成)**
检索增强生成是一种将信息检索系统与大型语言模型相结合的技术框架。在回答用户查询时，RAG首先从一个外部知识库（如向量数据库）中检索出最相关的文档片段，然后将这些片段作为上下文信息与用户问题一并提供给LLM，让其基于此生成答案。这种方法有效降低了LLM的“幻觉”现象，使其能够访问最新、更专有的知识，而无需重新训练模型。

**7. Agent (智能体)**
在AI语境下，智能体是指能够感知环境、进行决策并执行动作以达成目标的系统。LLM驱动的智能体利用大语言模型作为其“大脑”，进行规划、推理和工具调用。它们可以通过API、代码解释器等外部工具与环境交互，自主完成复杂任务链（如上网搜索、分析数据、撰写报告）。Agent代表了LLM从被动文本生成器转向主动问题解决者的演进。

**8. LangChain**
LangChain是一个用于开发由LLM驱动的应用程序的流行开源框架。它提供了模块化的抽象和组件（如Models, Prompts, Chains, Agents, Memory），让开发者能够轻松地将LLM与外部数据源、计算工具等连接起来，构建复杂的应用链。LangChain简化了RAG、智能体等高级模式的实现，是快速原型和部署LLM应用的重要工具。

**9. LangGraph**
LangGraph是建立在LangChain之上的一个库，它引入了基于状态图的编程模型来构建复杂、有状态的多智能体应用程序。它允许开发者将应用流程建模为图，其中节点代表执行步骤（如调用LLM或工具），边代表控制流。这使得管理长时间运行、具有循环和条件分支的对话或工作流（如多Agent协作）变得更加清晰和强大。

**10. 幻觉**
幻觉是指LLM生成的内容看似流畅合理，但实际上与输入不符或违背事实/常识的现象。例如，编造不存在的引用、给出错误答案或描述虚假事件。其根源在于LLM是基于统计模式而非事实数据库进行生成。缓解策略包括使用最新高质量数据训练、采用RAG提供真实上下文、通过提示工程引导模型以及让模型对生成内容进行溯源验证。



